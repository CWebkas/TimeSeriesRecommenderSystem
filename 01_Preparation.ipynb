{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Preparation\"\n",
    "author: \"Lukas Weixler\"\n",
    "date: \"26 7 2021\"\n",
    "output: html_document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "if (!require(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(tidyverse, ggfortify, zoo, forecast, tsfeatures, parallel, data.table, furrr, tictoc, janitor, data.table)\n",
    "library(M4metalearning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Remove duplicate Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rows <- ts_dataframe %>% pivot_wider(id_cols = 'id', values_from='Y', names_from='date')\n",
    "\n",
    "unique_ts <- ts_rows %>% distinct_at(vars(-id), .keep_all=T) %>% select(id)\n",
    "\n",
    "SPdata_reduced <- SPdata[unique_ts$id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Rename lst elements appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SPdata_reduced <- lapply(SPdata_reduced, seriesrenamR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_feats <- lapply(SPdata_reduced[1:10],tsfresh_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Hyndman_Feats <- THA_features(SPdata_reduced[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Map both feature groups into one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats <- map2(tsfresh_feats, Hyndman_Feats, featconnectR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_df <- data.frame(matrix(unlist(all_feats), nrow = length(all_feats), byrow = T))\n",
    "\n",
    "names(all_feats_df) <- names(all_feats[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Reduce perfectly correlating elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cormat <- cor(all_feats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Kick Rows with only NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ColNums_NotAllMissing <- function(df){ # helper function\n",
    "  out <- as.vector(which(colSums(is.na(df)) != nrow(df)-1))\n",
    "  return(out)\n",
    "}\n",
    "\n",
    "delete.na <- function(DF, n=0) {\n",
    "  return(DF[rowSums(is.na(DF)) <= n,])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Reduce elements with all misssings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cordf <- data.frame(cormat) %>% select(ColNums_NotAllMissing(.))\n",
    "\n",
    "cormat_reduced <- as.matrix(delete.na(cordf, 292))\n",
    "\n",
    "cordf_reduced <- data.frame(cormat_reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordf_reduced %>% gather(X, value) %>% \n",
    "  filter(value >=0.999999999999) %>% \n",
    "  tally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(cormat_reduced)['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Show number of 1s per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out <- cordf_reduced %>% gather(X, value) %>% \n",
    "  filter(value  >=0.999999999999) %>% \n",
    "  group_by(X) %>% \n",
    "  tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Store elements with more than 1 element having corr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noDups <- out %>% filter(n ==1) %>% select(X) \n",
    "\n",
    "final_df <- cordf_reduced[,c(noDups$X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "grouping <- c(names(final_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Syntactical adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(all_feats_df) <- gsub('\"', '.', names(all_feats_df))\n",
    "\n",
    "names(all_feats_df) <- gsub(',', '.', names(all_feats_df))\n",
    "\n",
    "names(all_feats_df) <- gsub(' ', '.', names(all_feats_df))\n",
    "\n",
    "names(all_feats_df) <- gsub('[()]', '.', names(all_feats_df))\n",
    "\n",
    "names(all_feats_df) <- gsub('-', '.', names(all_feats_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "available_feats <- all_feats_df[,grouping]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Normalization of available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "available_feats_normed <- py_scaler(available_feats) %>% as_data_frame()\n",
    "\n",
    "names(available_feats_normed) <- names(available_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Add new feats to dataset\n",
    "\n",
    "for (i in 1:length(SPdata_reduced)){\n",
    "SPdata_reduced[[i]]$features <- round(available_feats_normed[i,], 7)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Calculate forecasts for SPData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "SPdata_holdout <- temp_holdout(SPdata_reduced)\n",
    "\n",
    "tic()\n",
    "SPdata_forecasted <- calc_forecasts(SPdata_holdout, c('naive_forec', 'snaive_forec', 'stlm_ar_forec', 'ets_forec', 'rw_drift_forec', 'thetaf_forec', 'auto_arima_forec', 'nnetar_forec'), n.cores=11)\n",
    "toc()\n",
    "\n",
    "save(SPdata_forecasted, file = '../data/SPdata_forecasted.RData')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Check for NA Inf and huge errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "sptrain <- calc_errors(SPdata_forecasted)\n",
    "\n",
    "\n",
    "idxlst <- unlist(lapply(1:length(sptrain),function(i){if(any(is.na(sptrain[[i]]$mase_err)) | any(is.infinite(sptrain[[i]]$mase_err))){return(i)}}))\n",
    "\n",
    "\n",
    "spdat_reduced <- SPdata_forecasted[-idxlst] \n",
    "\n",
    "spdat_reduced <- calc_errors(spdat_reduced[-c(23545, 4771, 27102)])\n",
    "\n",
    "train_data <- create_feat_classif_problem(spdat_reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "name,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
