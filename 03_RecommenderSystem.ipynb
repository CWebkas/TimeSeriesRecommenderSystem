{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"03_RecommenderSystem\"\n",
    "author: \"Lukas Weixler\"\n",
    "date: \"26 7 2021\"\n",
    "output: html_document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pacman::p_load(tidyverse, mltools)\n",
    "library(M4metalearning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Import required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"~/data/SPDat_reduced_all.RData\")\n",
    "load(\"~/data/spdat_reduced_cls.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2021)\n",
    "indices <- sample(length(spdat_reduced_all))\n",
    "\n",
    "\n",
    "to_train <- length(indices)*0.8\n",
    "from_test <- length(indices)*0.8+1\n",
    "\n",
    "\n",
    "\n",
    "SPdata_train <- spdat_reduced_all[indices[1:to_train]]\n",
    "\n",
    "SPdata_test <-spdat_reduced_all[indices[from_test:length(indices)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 1. Standard Model runthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comment": false,
    "lines_to_next_cell": 0,
    "warning": false
   },
   "outputs": [],
   "source": [
    "\n",
    "SPdata_train <- calc_errors(SPdata_train)\n",
    "\n",
    "\n",
    "train_data <- create_feat_classif_problem(SPdata_train)\n",
    "\n",
    "\n",
    "# params are left default except for parallelization\n",
    "        param <- list(max_depth=14, eta=0.575188, nthread = 11, silent=1,\n",
    "                  objective=error_softmax_obj,\n",
    "                  num_class=ncol(train_data$errors),\n",
    "                  subsample=0.9161483,\n",
    "                  colsample_bytree=0.7670739\n",
    "    )\n",
    "\n",
    "\n",
    "set.seed(1345) #set the seed because xgboost is random!\n",
    "meta_model <- train_selection_ensemble(train_data$data, train_data$errors)\n",
    "\n",
    "\n",
    "\n",
    "# In order to create the newdata matrix required, the function create_feat_classif_problem can be used, it just produces the data object, not errors and labels.\n",
    "test_data <- create_feat_classif_problem(SPdata_test)\n",
    "\n",
    "\n",
    "\n",
    "# predict takes as parameters the model and a matrix with the features of the series. It outputs the predictions of the metalearning model, a matrix with the weights of the linear combination of methods, one row for each series.\n",
    "\n",
    "preds <- predict_selection_ensemble(meta_model, test_data$data)\n",
    "\n",
    "\n",
    "# The last step is calculating the actual forecasts by the linear combinations produced by the metalearning model.\n",
    "tstdat <- ensemble_forecast(preds, SPdata_test)\n",
    "\n",
    "summary <- summary_performance(preds, dataset = tstdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#2 Run the pipeline using optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comment": false,
    "warning": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate forecast errors for each method\n",
    "SPdata_train <- calc_errors(SPdata_train)\n",
    "\n",
    "# Rank methods based on softmax logic\n",
    "train_data <- create_feat_classif_problem(SPdata_train)\n",
    "\n",
    "\n",
    "# set the parameters based on optimization runthrough\n",
    "    param <- list(max_depth=11, eta=0.5543024, nthread = 11, silent=1,\n",
    "                  objective=error_softmax_obj,\n",
    "                  num_class=ncol(train_data$errors),\n",
    "                  subsample=0.9532598,\n",
    "                  colsample_bytree=1\n",
    "    )\n",
    "\n",
    "\n",
    "set.seed(1345) #set the seed because xgboost is random\n",
    "\n",
    "# Train\n",
    "meta_model <- train_selection_ensemble(train_data$data, train_data$errors, param=param)\n",
    "\n",
    "\n",
    "\n",
    "# In order to create the newdata matrix required, the function create_feat_classif_problem can be used, it just produces the data object, not errors and labels.\n",
    "test_data <- create_feat_classif_problem(SPdata_test)\n",
    "\n",
    "\n",
    "\n",
    "# predict takes as parameters the model and a matrix with the features of the series. It outputs the predictions of the metalearning model, a matrix with the weights of the linear combination of methods, one row for each series.\n",
    "\n",
    "preds <- predict_selection_ensemble(meta_model, test_data$data)\n",
    "\n",
    "\n",
    "# The last step is calculating the actual forecasts by the linear combinations produced by the metalearning model.\n",
    "tstdat <- ensemble_forecast(preds, SPdata_test)\n",
    "\n",
    "summary <- summary_performance(preds, dataset = tstdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Hyperparameter Tuning (will run multiple hours!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pms = hyperparameter_search(SPdata_train, filename = 'find_hyper.RData', n_iter = 500, n.cores=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 3. All Cluster labels\n",
    "\n",
    "### Import Cluster-labelled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"~/data/spdat_reduced_cls.RData\")\n",
    "\n",
    "sp_cls <- spdat_reduced_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Save cls_label as only feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:length(sp_cls)){\n",
    "  sp_cls[[i]]$features <- sp_cls[[i]]$cls_info[,\"cls_label\"]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls_dat <- c()\n",
    "for(i in 1:length(sp_cls)){\n",
    "  cls_dat[length(cls_dat)+1]<- sp_cls[[i]]$features\n",
    "}\n",
    "\n",
    "cls_dat <- data.table::data.table(cls=as_factor(unlist(cls_dat)))\n",
    "\n",
    "\n",
    "dt <- one_hot(cls_dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Save as one hot encoded feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for(i in 1:length(sp_cls)){\n",
    "  sp_cls[[i]]$features <- dt[i,]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test SPlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "set.seed(2021)\n",
    "indices <- sample(length(sp_cls))\n",
    "\n",
    "\n",
    "to_train <- length(indices)*0.8\n",
    "from_test <- length(indices)*0.8+1\n",
    "\n",
    "\n",
    "SPdata_train <- sp_cls[indices[1:to_train]]\n",
    "\n",
    "SPdata_test <-sp_cls[indices[from_test:length(indices)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Run Hyndman Pipeline with the single one hot encoded cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comment": false,
    "lines_to_next_cell": 2,
    "warning": false
   },
   "outputs": [],
   "source": [
    "\n",
    "SPdata_train <- calc_errors(SPdata_train)\n",
    "\n",
    "\n",
    "train_data <- create_feat_classif_problem(SPdata_train)\n",
    "\n",
    "\n",
    "# set the parameters based on optimization runthrough\n",
    "    param <- list(max_depth=14, eta=0.575188, nthread = 11, silent=1,\n",
    "                  objective=error_softmax_obj,\n",
    "                  num_class=ncol(train_data$errors),\n",
    "                  subsample=0.9161483,\n",
    "                  colsample_bytree=0.7670739\n",
    "    )\n",
    "\n",
    "\n",
    "set.seed(1345) #set the seed because xgboost is random!\n",
    "meta_model <- train_selection_ensemble(train_data$data, train_data$errors, param=param)\n",
    "\n",
    "\n",
    "\n",
    "# In order to create the newdata matrix required, the function create_feat_classif_problem can be used, it just produces the data object, not errors and labels.\n",
    "test_data <- create_feat_classif_problem(SPdata_test)\n",
    "\n",
    "\n",
    "\n",
    "# predict takes as parameters the model and a matrix with the features of the series. It outputs the predictions of the metalearning model, a matrix with the weights of the linear combination of methods, one row for each series.\n",
    "\n",
    "preds <- predict_selection_ensemble(meta_model, test_data$data)\n",
    "\n",
    "\n",
    "# The last step is calculating the actual forecasts by the linear combinations produced by the metalearning model.\n",
    "tstdat <- ensemble_forecast(preds, SPdata_test)\n",
    "\n",
    "summary <- summary_performance(preds, dataset = tstdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Only Sampled Cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "sp_cls <- c()\n",
    "\n",
    "for (i in 1:length(spdat_reduced_all)){\n",
    "  if(spdat_reduced_all[[i]]$cls_information$insamp == 1 ){\n",
    "  sp_cls[[length(sp_cls)+1]] <- spdat_reduced_all[[i]]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cls_label as only feature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for(i in 1:length(sp_cls)){\n",
    "  sp_cls[[i]]$features <- sp_cls[[i]]$cls_info[,\"cls_label\"]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls_dat <- c()\n",
    "for(i in 1:length(sp_cls)){\n",
    "  cls_dat[length(cls_dat)+1]<- sp_cls[[i]]$features\n",
    "}\n",
    "\n",
    "cls_dat <- data.table::data.table(cls=as_factor(unlist(cls_dat)))\n",
    "\n",
    "\n",
    "\n",
    "set.seed(2020)\n",
    "randsamps <-cls_dat %>% mutate(rownum=1:nrow(cls_dat)) %>%  group_by(cls) %>% sample_n(1)\n",
    "unsamped <- cls_dat %>% mutate(rownum=1:nrow(cls_dat)) %>% anti_join(randsamps)\n",
    "\n",
    "dt <- one_hot(cls_dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Save as one hot encoded feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for(i in 1:length(sp_cls)){\n",
    "  sp_cls[[i]]$features <- dt[i,]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test SPlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2021)\n",
    "indices <- sample(length(sp_cls))\n",
    "\n",
    "\n",
    "to_train <- length(indices)*0.8\n",
    "from_test <- length(indices)*0.8+1\n",
    "\n",
    "SPdata_train <- sp_cls[indices[1:to_train]]\n",
    "\n",
    "SPdata_test <-sp_cls[indices[from_test:length(indices)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Run Hyndman Pipeline with the single one hot encoded cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "SPdata_train <- calc_errors(SPdata_train)\n",
    "\n",
    "\n",
    "train_data <- create_feat_classif_problem(SPdata_train)\n",
    "\n",
    "\n",
    "# set the parameters based on optimization runthrough\n",
    "    param <- list(max_depth=14, eta=0.575188, nthread = 11, silent=1,\n",
    "                  objective=error_softmax_obj,\n",
    "                  num_class=ncol(train_data$errors),\n",
    "                  subsample=0.9161483,\n",
    "                  colsample_bytree=0.7670739\n",
    "    )\n",
    "\n",
    "\n",
    "set.seed(1345) #set the seed because xgboost is random!\n",
    "meta_model <- train_selection_ensemble(train_data$data, train_data$errors, param=param)\n",
    "\n",
    "\n",
    "\n",
    "# In order to create the newdata matrix required, the function create_feat_classif_problem can be used, it just produces the data object, not errors and labels.\n",
    "test_data <- create_feat_classif_problem(SPdata_test)\n",
    "\n",
    "\n",
    "\n",
    "# predict takes as parameters the model and a matrix with the features of the series. It outputs the predictions of the metalearning model, a matrix with the weights of the linear combination of methods, one row for each series.\n",
    "\n",
    "preds <- predict_selection_ensemble(meta_model, test_data$data)\n",
    "\n",
    "\n",
    "# The last step is calculating the actual forecasts by the linear combinations produced by the metalearning model.\n",
    "tstdat <- ensemble_forecast(preds, SPdata_test)\n",
    "\n",
    "summary <- summary_performance(preds, dataset = tstdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Model-Based feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat <- xgboost::xgb.importance (feature_names = colnames(test_data$data),\n",
    "                       model = meta_model)\n",
    "xgboost::xgb.plot.importance(importance_matrix = mat[1:15], cex=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Closer examination of single features among their quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tstfeats <- lapply(1:6408, function(i){SPdata_test[[i]]$features}) %>% bind_rows(.id = \"datnum\")\n",
    "\n",
    "\n",
    "\n",
    "featquantile <- quantile(tstfeats$Y__index_mass_quantile__q_0.9, probs = seq(0,1,0.1))\n",
    "\n",
    "\n",
    "# which elements in tstfeats are in which feature quantiles?\n",
    "\n",
    "featquantlst <- lapply(1:10,function(i){tstfeats[tstfeats$Y__index_mass_quantile__q_0.9>= featquantile[i]&\n",
    "           tstfeats$Y__index_mass_quantile__q_0.9< featquantile[i+1],]})\n",
    "\n",
    "# provide labels\n",
    "featquantlst <- lapply(1:10, function(i){featquantlst[[i]] %>% mutate(featquant = i)})\n",
    "\n",
    "# merge together\n",
    "featquantdf <- featquantlst %>% bind_rows() %>% mutate(datnum=as.numeric(datnum))\n",
    "\n",
    "\n",
    "# using datnum, add featquant to entries in preds\n",
    "\n",
    "predsdf <- as_data_frame(preds) \n",
    "\n",
    "names(predsdf)<- names(data.frame(train_data[[\"errors\"]]))\n",
    "\n",
    "\n",
    "datqtl <- predsdf %>% mutate(datnum = c(seq(1, 6408))) %>% left_join(featquantdf %>% select(datnum, featquant)) %>% group_by(featquant) %>% summarise_at(vars(-group_cols(), -datnum), mean) %>% rename() \n",
    "\n",
    "\n",
    "quantdat_ready <- reshape2::melt(datqtl, measure.vars = c(names(predsdf)))\n",
    "\n",
    "\n",
    "p1 <- ggplot(quantdat_ready, aes(fill=variable, y=value, x=featquant))+geom_bar(position = 'stack', stat='identity')+ggtitle(\"Index_mass_quantile_q_0.9\")+labs(x='Feature Quantile', fill=\"Forecast\", y=\"Average Probability\")+scale_fill_manual(values =c(\"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\",\"#999999\"))+scale_x_discrete(limits=c(1,2,3,4,5,6,7,8,9,10))\n",
    "\n",
    "\n",
    "# can be continued for less important features as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Feature Importance over entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "colours = c(\"1\" = \"#62879c\", \"2\" = \"#FF9900\", \"3\" = \"#CCFF00\", \"4\" = \"#fff478\", \"6\" = \"#00FF66\", \"7\"=\"#00FFFF\", \"8\"=\"#FF0000\", \"9\"=\"#3300FF\", \"5\"=\"#CC00FF\", \"0\"=\"#000000\")\n",
    "\n",
    "plt_allfeatimp <- mat %>% head(15) %>% rename(names = Feature) %>% \n",
    "  left_join(feat_importance_clustered %>% select(-importances), by='names') %>% \n",
    "  mutate(cls = as_factor(cls), names = gsub('_','.', names)) %>% \n",
    "  ggplot(aes(y=Gain, x=reorder(names, Gain), fill=cls))+geom_bar(stat='identity', position = 'dodge')+coord_flip()+\n",
    "  theme(axis.title.y = element_blank())+\n",
    "  scale_fill_manual(values=colours)\n",
    "\n",
    "plt_allfeatimp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Probabilities for forecasting methods\n",
    "\n",
    "### Max Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_proba <- tibble(\n",
    "  max_probability = factor(max.col(preds), \n",
    "  labels = names(data.frame(train_data[[\"errors\"]])))) %>% group_by(max_probability) %>% tally() %>% \n",
    "  rename(method.name = max_probability, count = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Mean Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "mean_proba <- tibble(\n",
    "  method_name = names(data.frame(train_data[[\"errors\"]])), \n",
    "  column_avg = colSums(preds)/nrow(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mean_proba <- tibble(\n",
    "  method_name = names(data.frame(train_data[[\"errors\"]])), \n",
    "  column_avg = colSums(preds)/nrow(preds))\n",
    "\n",
    "mean_proba <- mean_proba %>% mutate(method_name = gsub('_','.', method_name)) %>% rename(columnAverage = column_avg)\n",
    "\n",
    "\n",
    "# plotting the share of maximum for each method\n",
    "\n",
    "\n",
    "max_proba <- max_proba %>% mutate(method.name = gsub('_', '.', method.name))\n",
    "\n",
    "maxplt <- ggplot(max_proba,aes(x=method.name, y=count))+\n",
    "#  scale_x_discrete(limits=mean_proba$method_name)+\n",
    "  geom_bar(fill = c(\"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\",\"#999999\"), stat='identity')+\n",
    "  scale_x_discrete(limits=max_proba$method.name)+\n",
    "  ggtitle('Largest probabilities')+\n",
    "    theme(\n",
    "    axis.text.x = element_text(angle = 90),\n",
    "    axis.title.x = element_blank(),\n",
    "    title = element_text(size=12))\n",
    "\n",
    "# plotting the average probability for each method\n",
    "\n",
    "\n",
    "\n",
    "meanplt <-ggplot(mean_proba, aes(x=method_name, y=columnAverage))+geom_bar(fill = c(\"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\",\"#999999\"),stat='identity')+\n",
    "  scale_x_discrete(limits=mean_proba$method_name)+\n",
    "  ggtitle('Average probabilities')+  \n",
    "  theme(\n",
    "    axis.text.x = element_text(angle = 90),\n",
    "    axis.title.x = element_blank(),\n",
    "    title = element_text(size=12))\n",
    "\n",
    "maxplt\n",
    "meanplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Cluster-Specific Max Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_max_importance_plts <- lapply(0:39, function(i, colours =  c(\"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\",\"#999999\")){\n",
    "  cls_indxs <- labs %>% \n",
    "  filter(cls_lab == i) %>% \n",
    "  select(tstdat_indxno) %>% \n",
    "  unlist()\n",
    "\n",
    "# change prediction matrix to df\n",
    "predsdf <- data.frame(preds)\n",
    "\n",
    "# renaming prediction df to our methods\n",
    "names(predsdf) <- names(data.frame(train_data[[\"errors\"]]))\n",
    "\n",
    "# selecting rows of interest\n",
    "sub_tstdat <- predsdf[cls_indxs,]\n",
    "\n",
    "\n",
    "\n",
    "max_proba <- tibble(max_probability = factor(max.col(sub_tstdat), ))\n",
    "\n",
    "# selector tool for relevant algorithms\n",
    "apparent_algos <- sort(unlist(unique(max_proba$max_probability)))\n",
    "\n",
    "# plotting the share of maximum for each method\n",
    "ggplot(max_proba, \n",
    "       aes(max_probability))+\n",
    "  geom_bar(aes(y =(..count..)/sum(..count..)), fill=colours[apparent_algos])+\n",
    "  scale_fill_manual(values = c('orange', 'green'))+\n",
    "  ggtitle(paste('Share of most probable methods in cls ', i))+\n",
    "  scale_x_discrete(labels = names(sub_tstdat)[apparent_algos])+\n",
    "  theme(\n",
    "    axis.text.x = element_text(angle = 90, size=20),\n",
    "    title = element_text(size=25))\n",
    "\n",
    "\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Cluster-Specific Mean importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cls_mean_importance_plts <- lapply(0:39, function(i, colours = c(\"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\",\"#999999\")){\n",
    "  cls_indxs <- labs %>% \n",
    "  filter(cls_lab == i) %>% \n",
    "  select(tstdat_indxno) %>% \n",
    "  unlist()\n",
    "\n",
    "# change prediction matrix to df\n",
    "predsdf <- data.frame(preds)\n",
    "\n",
    "# renaming prediction df to our methods\n",
    "names(predsdf) <- names(data.frame(train_data[[\"errors\"]]))\n",
    "\n",
    "# selecting rows of interest\n",
    "sub_tstdat <- predsdf[cls_indxs,]\n",
    "\n",
    "\n",
    "\n",
    "mean_proba <- tibble(\n",
    "  method_name =names(data.frame(train_data[[\"errors\"]])), \n",
    "  column_avg = colSums(sub_tstdat)/nrow(sub_tstdat))\n",
    "\n",
    "# selector tool for relevant algorithms\n",
    "#apparent_algos <- sort(unlist(unique(mean_proba$column_avg)))\n",
    "\n",
    "# plotting the share of maximum for each method\n",
    "ggplot(mean_proba, \n",
    "       aes(x=method_name, y=column_avg))+\n",
    "  geom_bar(stat='identity',fill=colours)+\n",
    "  ggtitle(paste('Avg probability in each cls ', i))+\n",
    "  scale_x_discrete(limits=mean_proba$method_name)+\n",
    "  theme(\n",
    "    axis.text.x = element_text(angle = 90, size=20),\n",
    "    title = element_text(size=25))\n",
    "\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,comment,name,warning,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
